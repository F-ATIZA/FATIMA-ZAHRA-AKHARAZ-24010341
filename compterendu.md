## Photo personnelle

<img src="akharazfatimazahra.jpeg" style="height:464px;margin-right:432px"/>

**NumÃ©ro d'Ã©tudiant** : 24010341

**Classe** : CAC1

[compte_rendu_heart_disease.md](https://github.com/user-attachments/files/24082548/compte_rendu_heart_disease.md)
# ğŸ“˜ GRAND GUIDE : ANATOMIE D'UN PROJET DATA SCIENCE â€” HEART DISEASE EDITION

---

## 1. ğŸ¯ Contexte MÃ©tier et Mission

### Le ProblÃ¨me (Business Case)
Les maladies cardiovasculaires sont lâ€™une des premiÃ¨res causes de mortalitÃ© dans le monde. Leur dÃ©tection prÃ©coce repose souvent sur lâ€™analyse dâ€™indicateurs cliniques : ECG, pression artÃ©rielle, cholestÃ©rol, etc.

**Objectif :** Construire un modÃ¨le prÃ©dictif capable dâ€™estimer la probabilitÃ© quâ€™un patient souffre dâ€™une maladie cardiaque.

**Enjeu critique :**
- **Faux NÃ©gatif (FN)** : considÃ©rer un patient malade comme sain â†’ risque vital.
- **Faux Positif (FP)** : considÃ©rer un patient sain comme malade â†’ stress + examens coÃ»teux.

Dans ce contexte, **le Recall (SensibilitÃ©)** est la mÃ©trique prioritaire.

### Les DonnÃ©es (Input)
Nous utilisons le **Heart Disease UCI Dataset**.

- **X (features)** : Ã¢ge, sexe, pression sanguine, cholestÃ©rol, frÃ©quence cardiaque maximale, douleurs thoraciques, rÃ©sultats ECG, etc.
- **y (target)** : indicateur binaire (0 = pas de maladie, 1 = maladie).

---

## 2. ğŸ§ª Le Code Python (Laboratoire)

Ce code se base sur votre script avec :
- Nettoyage des donnÃ©es
- PrÃ©paration des variables
- Split Train/Test
- ModÃ©lisation via **Random Forest Classifier**

```python
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
```

Lâ€™algorithme utilisÃ© est donc **Random Forest**, robuste et performant pour les donnÃ©es tabulaires.

---

## 3. ğŸ”§ Analyse Approfondie : Nettoyage (Data Wrangling)

### Pourquoi nettoyer ?
Les valeurs `NaN` perturbent complÃ¨tement les calculs matriciels. Elles doivent donc Ãªtre imputÃ©es.

### StratÃ©gie adoptÃ©e
- Variables numÃ©riques : imputation par **mÃ©diane** (rÃ©sistant aux valeurs extrÃªmes)
- Variables catÃ©gorielles : imputation par **mode**
- Conversion des colonnes boolÃ©ennes (`fbs`, `exang`)

### Attention au Data Leakage
Lâ€™imputation doit idÃ©alement se faire **aprÃ¨s** le split (Train puis Test), pas avant.

---

## 4. ğŸ” Analyse Exploratoire (EDA)

Les analyses effectuÃ©es dans votre script incluent :
- **Heatmap de corrÃ©lations**
- **Histogrammes**
- **Scatter plots** (relations entre features et maladie)

### Observations principales
- `thalach` (frÃ©quence max) est nÃ©gativement corrÃ©lÃ© avec la maladie.
- `oldpeak`, `ca`, et `exang` sont fortement associÃ©s Ã  la prÃ©sence de maladie.
- Certaines variables prÃ©sentent une forte asymÃ©trie.

---

## 5. ğŸ”¬ Analyse MÃ©thodologique (Split)

Le split utilisÃ© :

```python
train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
```

### Rappels importants :
- **80/20** est un standard Ã©quilibrÃ©.
- `random_state=42` assure la reproductibilitÃ©.
- `stratify=y` maintient la proportion malade/sain dans les deux ensembles.

---

## 6. ğŸŒ² Focus ThÃ©orique : Random Forest

Cet algorithme fonctionne selon trois mÃ©canismes :

### A. Les arbres de dÃ©cision (faibles mais rapides)
Un arbre seul a une **haute variance** : il surapprend facilement.

### B. Le bagging (stabilisation)
Chaque arbre sâ€™entraÃ®ne sur :
- un **Ã©chantillon bootstrap** (patients tirÃ©s alÃ©atoirement avec remise),
- un **sous-ensemble alÃ©atoire de colonnes**.

Cela crÃ©e une diversitÃ© dâ€™arbres â†’ robustesse.

### C. Le vote majoritaire
Chaque arbre â€œvoteâ€.  
Le modÃ¨le final suit lâ€™opinion majoritaire â†’ meilleure gÃ©nÃ©ralisation.

---

## 7. ğŸ“Š Ã‰valuation du ModÃ¨le (L'Heure de VÃ©ritÃ©)

### Matrice de Confusion
Les 4 types de prÃ©dictions sont analysÃ©s :
- **TP** : malade bien dÃ©tectÃ©
- **TN** : sain correctement identifiÃ©
- **FP** : faux alarmes
- **FN** : patients malades non dÃ©tectÃ©s â†’ critique

### MÃ©triques
Lâ€™accuracy seule est trompeuse.  
On privilÃ©gie :
- **Recall** (Ã©viter les FN),
- **Precision** (fiabilitÃ© des alertes),
- **F1-score** : compromis global.

---

## ğŸ¯ Conclusion Finale

Ce projet montre que :
- la comprÃ©hension mÃ©tier est essentielle,
- la Data Science est un processus structurÃ©,
- le Random Forest convient bien aux donnÃ©es mÃ©dicales tabulaires,
- lâ€™Ã©valuation doit se concentrer sur la sÃ©curitÃ© (Recall),
- une bonne pipeline (nettoyage â†’ EDA â†’ split â†’ modÃ¨le â†’ audit) garantit la fiabilitÃ© du systÃ¨me.

Ce rapport constitue une base solide pour un projet acadÃ©mique ou une application mÃ©dicale plus poussÃ©e.
